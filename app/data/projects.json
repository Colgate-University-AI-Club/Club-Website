[
  {
    "id": "p1",
    "slug": "sentiment-classifier",
    "title": "Twitter Sentiment Analysis Classifier",
    "level": "beginner",
    "projectType": "code",
    "tools": ["Python", "scikit-learn", "Pandas", "Jupyter"],
    "durationHours": 4,
    "summary": "Build a machine learning model to classify tweets as positive, negative, or neutral using Python and scikit-learn.",
    "repoUrl": "https://github.com/Colgate-University-AI-Club/sentiment-classifier",
    "resources": [
      {
        "label": "Google Colab",
        "url": "https://colab.research.google.com"
      },
      {
        "label": "scikit-learn Documentation",
        "url": "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
      },
      {
        "label": "Twitter Dataset",
        "url": "https://www.kaggle.com/datasets/kazanova/sentiment140"
      },
      {
        "label": "Natural Language Processing Basics",
        "url": "https://realpython.com/nltk-nlp-python/"
      }
    ],
    "body": "## Project Overview\n\nSentiment analysis is one of the most popular applications of Natural Language Processing (NLP). In this beginner-friendly project, you'll build a machine learning classifier that can automatically determine whether a tweet expresses positive, negative, or neutral sentiment.\n\n## Learning Objectives\n\nBy completing this project, you will:\n- Understand the fundamentals of text classification\n- Learn how to preprocess text data for machine learning\n- Implement feature extraction using TF-IDF vectorization\n- Train and evaluate a Naive Bayes classifier\n- Visualize model performance with confusion matrices\n\n## Prerequisites\n\n- Basic Python programming knowledge\n- Familiarity with pandas and NumPy (helpful but not required)\n- Understanding of basic ML concepts (training/testing split, accuracy)\n- Google account for Colab access\n\n## Step-by-Step Guide\n\n### 1. Environment Setup\n\nOpen Google Colab and create a new notebook. Install required packages:\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\n```\n\n### 2. Load and Explore the Dataset\n\nDownload the Sentiment140 dataset from Kaggle and load it into your notebook:\n\n```python\n# Load the dataset\ndf = pd.read_csv('training.csv', encoding='latin-1', header=None)\ndf.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n\n# Explore the data\nprint(df.head())\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Sentiment distribution:\\n{df['target'].value_counts()}\")\n```\n\n### 3. Data Preprocessing\n\nClean and prepare the text data:\n\n```python\nimport re\nimport string\n\ndef clean_text(text):\n    # Remove URLs\n    text = re.sub(r'http\\S+', '', text)\n    # Remove mentions and hashtags\n    text = re.sub(r'@\\w+|#\\w+', '', text)\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    # Convert to lowercase\n    text = text.lower()\n    return text\n\ndf['clean_text'] = df['text'].apply(clean_text)\n```\n\n### 4. Train-Test Split\n\n```python\nX = df['clean_text']\ny = df['target']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n```\n\n### 5. Feature Extraction with TF-IDF\n\n```python\nvectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n```\n\n### 6. Train the Classifier\n\n```python\nclassifier = MultinomialNB()\nclassifier.fit(X_train_tfidf, y_train)\n```\n\n### 7. Evaluate Performance\n\n```python\ny_pred = classifier.predict(X_test_tfidf)\n\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n```\n\n### 8. Test with Custom Tweets\n\n```python\ndef predict_sentiment(text):\n    clean = clean_text(text)\n    vec = vectorizer.transform([clean])\n    prediction = classifier.predict(vec)[0]\n    return \"Positive\" if prediction == 4 else \"Negative\"\n\n# Try it out!\ntest_tweets = [\n    \"I love this new AI project!\",\n    \"This is the worst experience ever.\",\n    \"The weather is nice today.\"\n]\n\nfor tweet in test_tweets:\n    print(f\"Tweet: {tweet}\")\n    print(f\"Sentiment: {predict_sentiment(tweet)}\\n\")\n```\n\n## Expected Outcomes\n\n- A trained sentiment classifier with 75-80% accuracy\n- Understanding of text preprocessing techniques\n- Experience with scikit-learn's ML pipeline\n- A reusable prediction function for new tweets\n\n## Next Steps\n\n- Try different classifiers (Logistic Regression, SVM)\n- Experiment with word embeddings (Word2Vec, GloVe)\n- Add neutral sentiment classification\n- Deploy your model as a web API using Flask\n\n## Troubleshooting\n\n**Issue**: Low accuracy\n- Solution: Increase max_features in TfidfVectorizer or try different preprocessing\n\n**Issue**: Out of memory errors\n- Solution: Use a smaller sample of the dataset or reduce max_features\n\n**Issue**: Slow training\n- Solution: Enable GPU runtime in Colab (Runtime > Change runtime type > GPU)"
  },
  {
    "id": "p2",
    "slug": "course-rag-chatbot",
    "title": "Course-Specific RAG Chatbot",
    "level": "intermediate",
    "projectType": "no-code",
    "tools": ["n8n", "OpenAI API", "Pinecone", "Slack"],
    "durationHours": 3,
    "summary": "Build an AI chatbot that answers questions about your course materials using RAG (Retrieval-Augmented Generation)",
    "repoUrl": "https://github.com/Colgate-University-AI-Club/course-rag-chatbot",
    "resources": [
      {
        "label": "n8n RAG Tutorial",
        "url": "https://docs.n8n.io"
      },
      {
        "label": "Pinecone Docs",
        "url": "https://www.pinecone.io/docs/"
      }
    ],
    "body": "## Overview\n\nLearn to build a chatbot that can answer questions about course materials by combining document retrieval with AI generation.\n\n## What You'll Learn\n\n- RAG architecture basics\n- Vector databases (Pinecone)\n- Workflow automation with n8n\n- Integrating OpenAI API\n\n## Prerequisites\n\n- n8n account (free)\n- OpenAI API key\n- Pinecone account (free tier)\n- Course PDFs or documents"
  },
  {
    "id": "p3",
    "slug": "flour-salt-website",
    "title": "Design Flour and Salt Restaurant Website",
    "level": "beginner",
    "projectType": "no-code",
    "tools": ["Lovable.dev", "Figma"],
    "durationHours": 2,
    "summary": "Create a beautiful restaurant website using AI-powered design tools - no coding required",
    "repoUrl": "https://github.com/Colgate-University-AI-Club/flour-salt-website",
    "resources": [
      {
        "label": "Lovable Documentation",
        "url": "https://lovable.dev/docs"
      },
      {
        "label": "Restaurant Design Tips",
        "url": "https://www.figma.com"
      }
    ],
    "body": "## Overview\n\nUse AI-powered design tools to create a professional restaurant website in hours, not days.\n\n## What You'll Build\n\n- Modern landing page\n- Menu showcase\n- Reservation form\n- Contact section\n\n## Tools Needed\n\n- Lovable.dev account\n- Restaurant images and menu"
  },
  {
    "id": "p4",
    "slug": "email-manager-agent",
    "title": "AI Email Manager Agent",
    "level": "beginner",
    "projectType": "no-code",
    "tools": ["n8n", "OpenAI API", "Gmail"],
    "durationHours": 2,
    "summary": "Build an AI agent that automatically categorizes, prioritizes, and drafts responses to your emails",
    "repoUrl": "https://github.com/Colgate-University-AI-Club/email-manager-agent",
    "resources": [
      {
        "label": "n8n Gmail Integration",
        "url": "https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.gmail/"
      },
      {
        "label": "OpenAI API Guide",
        "url": "https://platform.openai.com/docs"
      }
    ],
    "body": "## Overview\n\nAutomate your email workflow using AI to save hours every week.\n\n## Features\n\n- Auto-categorize emails (urgent/spam/personal/work)\n- Priority scoring\n- AI-generated draft responses\n- Smart notifications\n\n## Setup\n\nConnect your Gmail account to n8n, configure OpenAI API, and set up categorization rules."
  },
  {
    "id": "p5",
    "slug": "ai-image-marketing",
    "title": "AI Image Generation for Product Marketing",
    "level": "intermediate",
    "projectType": "no-code",
    "tools": ["Make.com", "DALL-E API", "Airtable", "Slack"],
    "durationHours": 3,
    "summary": "Create an automated pipeline that generates marketing images for products using AI",
    "repoUrl": "https://github.com/Colgate-University-AI-Club/ai-image-marketing",
    "resources": [
      {
        "label": "Make.com Tutorials",
        "url": "https://www.make.com/en/help/tutorials"
      },
      {
        "label": "DALL-E API Docs",
        "url": "https://platform.openai.com/docs/guides/images"
      }
    ],
    "body": "## Overview\n\nBuild an end-to-end workflow that takes product descriptions and automatically generates marketing images.\n\n## Workflow Steps\n\n1. Product info entered in Airtable\n2. Make.com triggers on new entries\n3. DALL-E generates product images\n4. Images saved to cloud storage\n5. Team notified via Slack\n\n## Use Cases\n\n- E-commerce product photos\n- Social media content\n- Marketing campaigns"
  },
  {
    "id": "p6",
    "slug": "lead-generation-system",
    "title": "AI-Powered Lead Generation System",
    "level": "advanced",
    "projectType": "hybrid",
    "tools": ["Python", "n8n", "OpenAI API", "LinkedIn API", "PostgreSQL"],
    "durationHours": 8,
    "summary": "Build a complete lead generation system that finds, scores, and reaches out to potential leads automatically",
    "repoUrl": "https://github.com/Colgate-University-AI-Club/lead-generation-system",
    "resources": [
      {
        "label": "LinkedIn API Docs",
        "url": "https://docs.microsoft.com/en-us/linkedin/"
      },
      {
        "label": "Lead Scoring Guide",
        "url": "https://www.salesforce.com"
      }
    ],
    "body": "## Overview\n\nCombine Python scripts with automation tools to build a professional lead generation pipeline.\n\n## System Architecture\n\n- **Python**: Web scraping, data processing, ML-based lead scoring\n- **n8n**: Workflow orchestration, email outreach\n- **PostgreSQL**: Lead database\n- **OpenAI**: Personalized email generation\n\n## What You'll Learn\n\n- Web scraping ethics and techniques\n- Machine learning for lead scoring\n- API integration\n- Workflow automation"
  },
  {
    "id": "p7",
    "slug": "ai-insights-dashboard",
    "title": "AI Research Insights Dashboard",
    "level": "intermediate",
    "projectType": "code",
    "tools": ["Python", "Streamlit", "Pandas", "Plotly"],
    "durationHours": 5,
    "summary": "Create an interactive dashboard to visualize AI research trends and paper statistics",
    "repoUrl": "https://github.com/Colgate-University-AI-Club/ai-insights-dashboard",
    "resources": [
      {
        "label": "Streamlit Docs",
        "url": "https://docs.streamlit.io"
      },
      {
        "label": "Plotly Guide",
        "url": "https://plotly.com/python/"
      }
    ],
    "body": "## Overview\n\nBuild a beautiful dashboard that visualizes trends in AI research papers from ArXiv.\n\n## Features\n\n- Live data from ArXiv API\n- Interactive charts and graphs\n- Topic clustering visualization\n- Citation network analysis\n\n## Tech Stack\n\n- **Streamlit** for the web interface\n- **Pandas** for data processing\n- **Plotly** for interactive visualizations"
  }
]
